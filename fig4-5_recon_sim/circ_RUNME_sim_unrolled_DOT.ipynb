{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb5d504-aec7-4d59-9bcf-3620aedc8833",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import Compose, ToTensor, Resize, InterpolationMode\n",
    "\n",
    "import math\n",
    "import random\n",
    "import sys\n",
    "import h5py\n",
    "from scipy.io import savemat\n",
    "import configparser\n",
    "\n",
    "setpaths_dir = \"../setpaths\"\n",
    "sys.path.append(setpaths_dir)\n",
    "from setpaths import setpaths\n",
    "libpath, datpath, resultpath, basepath = setpaths(setpaths_dir)\n",
    "\n",
    "sys.path.append(basepath)\n",
    "from lib.DOTDataset_class import DOTDataset\n",
    "from lib.utils import train_model, showIms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5414b1-5819-4acd-8561-f0421539d9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_seed = 0\n",
    "np.random.seed(rand_seed)\n",
    "torch_seed = torch.manual_seed(rand_seed)\n",
    "\n",
    "GPUID = 5\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(GPUID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856838c0-55b2-4f63-ac37-59660656de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "# configname = \"unet_vgg_train_fashion_test_fashion.ini\"\n",
    "# configname = \"train_fashion_test_fashion.ini\"\n",
    "# configname = \"train_fashion_test_mnist.ini\"\n",
    "# configname = \"train_mnist_test_mnist.ini\"\n",
    "# configname = \"nLayers_experiment_train_test_mnist.ini\"\n",
    "configname = 'circphantom_test.ini'\n",
    "\n",
    "fullconfigpath = os.path.join(\"settings\", configname)\n",
    "config = configparser.ConfigParser()\n",
    "_ = config.read(fullconfigpath)\n",
    "\n",
    "# Forward model parameters\n",
    "jac_dir = config[\"Settings\"][\"jac_dir\"]\n",
    "abs_mua = float(config[\"Settings\"][\"abs_mua\"])\n",
    "bin_sz = int(config[\"Settings\"][\"bin_sz\"])\n",
    "int_time = float(config[\"Settings\"][\"int_time\"]) # Seconds\n",
    "pile_up = float(config[\"Settings\"][\"pile_up\"]) # Pile-up point in cnts/sec\n",
    "\n",
    "train_set_select = config[\"Settings\"][\"train_set_select\"] # 'f' for fashion mnist\n",
    "test_set_select = config[\"Settings\"][\"test_set_select\"] # 'm' for mnist\n",
    "\n",
    "# Training parameters\n",
    "nTrain = int(config[\"Settings\"][\"nTrain\"])\n",
    "nTest = int(config[\"Settings\"][\"nTest\"])\n",
    "batch_sz = int(config[\"Settings\"][\"batch_sz\"])\n",
    "# nLayers = int(config[\"Settings\"][\"nLayers\"])\n",
    "nLayers = [int(i) for i in config[\"Settings\"][\"nLayers\"].split(',')]\n",
    "LR = float(config[\"Settings\"][\"LR\"])\n",
    "scale_initial_val = LR\n",
    "nEpochs = int(config[\"Settings\"][\"nEpochs\"])\n",
    "lam1 = config.get(\"Settings\", \"lam1\", fallback=None) # if None use learnable L1 coefficient, else use lam1\n",
    "untied = config[\"Settings\"].getboolean(\"untied\")\n",
    "showEvery = int(config[\"Settings\"][\"showEvery\"])\n",
    "lossFunc = config[\"Settings\"][\"lossFunc\"]\n",
    "vgg_weight = float(config[\"Settings\"][\"vgg_weight\"])\n",
    "unet_nfilts = int(config[\"Settings\"][\"unet_nfilts\"])\n",
    "if len(config[\"Settings\"][\"displayIndices\"]) > 0:\n",
    "    displayIndices = [int(i) for i in config[\"Settings\"][\"displayIndices\"].split(',')]\n",
    "else:\n",
    "    displayIndices = []\n",
    "measNormalization = float(config[\"Settings\"][\"measNormalization\"])\n",
    "\n",
    "RUN_DEBUG = True\n",
    "debug_vis_inds = displayIndices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46aaac8-41ca-4f0b-afec-e0504f59272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in Jacobian\n",
    "\n",
    "J_full_fname = \"%s/%s/J_multisrc_interp.mat\" % (datpath, jac_dir)\n",
    "\n",
    "with h5py.File(J_full_fname, 'r') as f:\n",
    "    J = f[\"J_final\"][:]\n",
    "    Jheaders = f[\"Jheaders\"]\n",
    "    VOX_W = int(f[\"Jheaders\"][\"VOX_W\"][0][0])\n",
    "    VOX_L = int(f[\"Jheaders\"][\"VOX_W\"][0][0])\n",
    "    NBINS = int(f[\"Jheaders\"][\"NBINS\"][0][0])\n",
    "    SRC_W = int(f[\"Jheaders\"][\"SRC_W\"][0][0])\n",
    "    SRC_L = int(f[\"Jheaders\"][\"SRC_L\"][0][0])\n",
    "    SENS_W = int(f[\"Jheaders\"][\"SENS_W\"][0][0])\n",
    "    SENS_L = int(f[\"Jheaders\"][\"SENS_L\"][0][0])\n",
    "    bkg_sig = f[\"bkg_final\"][:]\n",
    "\n",
    "Jheaders_py = {\n",
    "    \"VOX_W\": VOX_W,\n",
    "    \"VOX_L\": VOX_L, \n",
    "    \"NBINS\": NBINS,\n",
    "    \"SRC_W\": SRC_W,\n",
    "    \"SRC_L\": SRC_L,\n",
    "    \"SENS_W\": SENS_W,\n",
    "    \"SENS_L\": SENS_L,\n",
    "}\n",
    "    \n",
    "J = torch.tensor(np.transpose(J, np.flip(range(len(J.shape)))), dtype=torch.float) # Invert dimensions in importing from matlab\n",
    "bkg_sig = torch.tensor(np.transpose(bkg_sig, np.flip(range(len(bkg_sig.shape)))), dtype=torch.float)\n",
    "\n",
    "nvox = np.prod([VOX_W, VOX_L])\n",
    "J = torch.reshape(J, (NBINS, -1, nvox))\n",
    "bkg_sig = torch.reshape(bkg_sig, (NBINS, -1))\n",
    "\n",
    "nsrcdet = J.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a640b33d-10ec-4cb3-9b63-5f934d08c190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in datasets (MNIST and Fashion MNIST)\n",
    "\n",
    "mnist_full_set = datasets.MNIST(\n",
    "    root=datpath,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "fashion_full_set = datasets.FashionMNIST(\n",
    "    root=datpath,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "print(\"Done loading datasets!\")\n",
    "\n",
    "len_mnist = len(mnist_full_set)\n",
    "len_fashion = len(fashion_full_set)\n",
    "\n",
    "fashion_inds = torch.randperm(len_fashion)\n",
    "mnist_inds = torch.randperm(len_mnist)\n",
    "\n",
    "fashion_set_shuffled = fashion_full_set.data[fashion_inds,:,:]\n",
    "mnist_set_shuffled = mnist_full_set.data[mnist_inds,:,:]\n",
    "\n",
    "# Process images so they are properly sized and max intensity equal to mu_a\n",
    "f_resize = Resize((VOX_W, VOX_L))\n",
    "\n",
    "if train_set_select.lower() == 'f':\n",
    "    train_dat = f_resize(fashion_set_shuffled[:nTrain,:,:].double())\n",
    "elif train_set_select.lower() == 'm':\n",
    "    train_dat = f_resize(mnist_set_shuffled[:nTrain,:,:].double())\n",
    "    \n",
    "if test_set_select.lower() == 'f':\n",
    "    test_dat = f_resize(fashion_set_shuffled[nTrain:(nTrain+nTest)].double())\n",
    "elif test_set_select.lower() == 'm':\n",
    "    test_dat = f_resize(mnist_set_shuffled[nTrain:(nTrain+nTest)].double())\n",
    "\n",
    "final_recon_vis = np.transpose(np.concatenate([train_dat[debug_vis_inds,:,:], test_dat[debug_vis_inds,:,:]]), (1,2,0))\n",
    "\n",
    "if len(displayIndices) > 0:\n",
    "    showIms(final_recon_vis)\n",
    "\n",
    "test_dat *= (abs_mua / torch.amax(test_dat, dim=(1,2)))[:,None,None]\n",
    "train_dat *= (abs_mua / torch.amax(train_dat, dim=(1,2)))[:,None,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae97131-7aa9-4487-b342-0f1d38698899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate noisy measurements\n",
    "\n",
    "nbins_final = math.ceil(NBINS / bin_sz)\n",
    "\n",
    "J_binned = torch.zeros((nbins_final, nsrcdet, nvox))\n",
    "bkg_binned = torch.zeros((nbins_final, nsrcdet))\n",
    "for t in range(nbins_final):\n",
    "    t_start = t*bin_sz\n",
    "    t_end = min((t+1)*bin_sz, NBINS)\n",
    "    J_binned[t,:,:] = torch.sum(J[t_start:t_end,:,:], dim=0)\n",
    "    bkg_binned[t,:] = torch.sum(bkg_sig[t_start:t_end,:], dim=0)\n",
    "\n",
    "# Reshape Jacobian to be able to multiply with images\n",
    "J_mat = torch.reshape(J_binned, (nbins_final, nsrcdet, nvox)).double()\n",
    "\n",
    "# Reshape images\n",
    "test_mu = torch.transpose(torch.reshape(test_dat, (-1, nvox)), 0, 1)\n",
    "train_mu = torch.transpose(torch.reshape(train_dat, (-1, nvox)), 0, 1)\n",
    "\n",
    "# Generate clean measurements: J*mu\n",
    "m_test_clean = J_mat @ test_mu\n",
    "m_train_clean = J_mat @ train_mu\n",
    "\n",
    "# Calculate normalization factor: integrate bkg in time domain, find the max\n",
    "normfac = (int_time * pile_up) / torch.amax(torch.sum(bkg_binned,0))\n",
    "\n",
    "# replicate bkg by number of samples, \n",
    "bkg_clean_test = bkg_binned[:,:,None].repeat((1,1,nTest))\n",
    "bkg_clean_train = bkg_binned[:,:,None].repeat((1,1,nTrain))\n",
    "\n",
    "# Measurement is bkg - J*mu\n",
    "abs_clean_test = torch.clip(bkg_clean_test - m_test_clean, min=0, max=None)\n",
    "abs_clean_train = torch.clip(bkg_clean_train - m_train_clean, min=0, max=None)\n",
    "\n",
    "# Scale the max background to be int_time*pile_up\n",
    "bkg_clean_test_norm = bkg_clean_test * normfac\n",
    "bkg_clean_train_norm = bkg_clean_train * normfac\n",
    "abs_clean_test_norm = abs_clean_test * normfac\n",
    "abs_clean_train_norm = abs_clean_train * normfac\n",
    "\n",
    "# Apply poisson noise then take the difference\n",
    "bkg_noisy_test = torch.poisson(bkg_clean_test_norm)\n",
    "bkg_noisy_train = torch.poisson(bkg_clean_train_norm)\n",
    "abs_noisy_test = torch.poisson(abs_clean_test_norm)\n",
    "abs_noisy_train = torch.poisson(abs_clean_train_norm)\n",
    "\n",
    "m_noisy_test_raw = bkg_noisy_test - abs_noisy_test\n",
    "m_noisy_train_raw = bkg_noisy_train - abs_noisy_train\n",
    "m_noisy_test = m_noisy_test_raw / normfac\n",
    "m_noisy_train = m_noisy_train_raw / normfac\n",
    "\n",
    "# Prepare Jacobian matrix\n",
    "J_mat_np = torch.reshape(J_mat, (nbins_final*nsrcdet, nvox)).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0640d9d-933e-42b3-8842-c5e3403993cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare model for training\n",
    "\n",
    "test_noisy_dat = m_noisy_test.cpu().detach().numpy()\n",
    "train_noisy_dat = m_noisy_train.cpu().detach().numpy()\n",
    "test_truth = torch.permute(test_dat, (1,2,0)).cpu().detach().numpy()\n",
    "train_truth = torch.permute(train_dat, (1,2,0)).cpu().detach().numpy()\n",
    "\n",
    "test_noisy_dat *= measNormalization / np.amax(test_noisy_dat)\n",
    "train_noisy_dat *= measNormalization / np.amax(train_noisy_dat)\n",
    "full_dataset = DOTDataset(trainMeas=train_noisy_dat, trainTruth=train_truth, testMeas=test_noisy_dat, testTruth=test_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07216158-ef20-422b-9a2e-5366e49cbbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_DEBUG:\n",
    "    with torch.no_grad():\n",
    "       \n",
    "        trainMeas, trainTruth = full_dataset.getFullTrainSet()\n",
    "        testMeas, testTruth = full_dataset.getFullTestSet()\n",
    "        \n",
    "        # Test that training images correctly corresponds to mnist, fashion mnist image\n",
    "        if train_set_select.lower() == 'm':\n",
    "            full_set_train = mnist_full_set.data[mnist_inds,:,:]\n",
    "        elif train_set_select.lower() == 'f':\n",
    "            full_set_train = fashion_full_set.data[fashion_inds,:,:]\n",
    "        for train_i in range(nTrain):\n",
    "            allDat_im = np.reshape(trainTruth[:,train_i].cpu().detach().numpy(), (VOX_W, VOX_L))\n",
    "            train_im = np.reshape(f_resize(full_set_train[train_i].double()[None,:,:]).cpu().detach().numpy(), (VOX_W, VOX_L)) \n",
    "            allDat_im /= np.amax(allDat_im)\n",
    "            train_im /= np.amax(train_im)\n",
    "            assert (np.allclose(allDat_im, train_im)), \"Training images do not match!\"\n",
    "        print(\"All Training Images Match!\")\n",
    "    \n",
    "        if test_set_select.lower() == 'm':\n",
    "            full_set_test = mnist_full_set.data[mnist_inds,:,:]\n",
    "        elif test_set_select.lower() == 'f':\n",
    "            full_set_test = fashion_full_set.data[fashion_inds,:,:]\n",
    "        for test_i in range(nTest):\n",
    "            allDat_im = np.reshape(testTruth[:,test_i].cpu().detach().numpy(), (VOX_W, VOX_L))\n",
    "            test_im = np.reshape(f_resize(full_set_test[nTrain+test_i].double()[None,:,:]).cpu().detach().numpy(), (VOX_W, VOX_L))\n",
    "            allDat_im /= np.amax(allDat_im)\n",
    "            test_im /= np.amax(test_im)\n",
    "            assert (np.allclose(allDat_im, test_im)), \"Testing images do not match!\"\n",
    "        print(\"All Testing Images Match!\")\n",
    "        print(\"\\n\")\n",
    "    \n",
    "        # Ensure no overlap\n",
    "        train_ims_check = trainTruth\n",
    "        test_ims_check = testTruth\n",
    "        for p in range(nTest):\n",
    "            im_p_test = torch.reshape(test_ims_check[:,p], (VOX_W, VOX_L))\n",
    "            for q in range(nTrain):\n",
    "                im_q_train = torch.reshape(train_ims_check[:,q], (VOX_W, VOX_L))\n",
    "                assert (not torch.allclose(im_p_test, im_q_train)), \"Found Overlap\"\n",
    "        print(\"Found no overlaps!\")\n",
    "        print(\"\\n\")\n",
    "    \n",
    "        # Visualize collocated measurements\n",
    "        if SRC_W*SRC_L*SENS_W*SENS_L == nsrcdet:\n",
    "            \n",
    "            bkg_clean_test_norm = torch.reshape(bkg_clean_test_norm, (nbins_final, SRC_W, SRC_L, SENS_W, SENS_L, nTest))\n",
    "            abs_clean_test_norm = torch.reshape(abs_clean_test_norm, (nbins_final, SRC_W, SRC_L, SENS_W, SENS_L, nTest))\n",
    "            bkg_noisy_test = torch.reshape(bkg_noisy_test, (nbins_final, SRC_W, SRC_L, SENS_W, SENS_L, nTest))\n",
    "            abs_noisy_test = torch.reshape(abs_noisy_test, (nbins_final, SRC_W, SRC_L, SENS_W, SENS_L, nTest))\n",
    "            m_noisy_test_raw = torch.reshape(m_noisy_test_raw, (nbins_final, SRC_W, SRC_L, SENS_W, SENS_L, nTest))\n",
    "            m_noisy_test_norm = torch.reshape(m_noisy_test, (nbins_final, SRC_W, SRC_L, SENS_W, SENS_L, nTest))\n",
    "            \n",
    "            bkg_clean_train_norm = torch.reshape(bkg_clean_train_norm, (nbins_final, SRC_W, SRC_L, SENS_W, SENS_L, nTrain))\n",
    "            abs_clean_train_norm = torch.reshape(abs_clean_train_norm, (nbins_final, SRC_W, SRC_L, SENS_W, SENS_L, nTrain))\n",
    "            bkg_noisy_train = torch.reshape(bkg_noisy_train, (nbins_final, SRC_W, SRC_L, SENS_W, SENS_L, nTrain))\n",
    "            abs_noisy_train = torch.reshape(abs_noisy_train, (nbins_final, SRC_W, SRC_L, SENS_W, SENS_L, nTrain))\n",
    "            m_noisy_train_raw = torch.reshape(m_noisy_train_raw, (nbins_final, SRC_W, SRC_L, SENS_W, SENS_L, nTrain))\n",
    "            m_noisy_train_norm = torch.reshape(m_noisy_train, (nbins_final, SRC_W, SRC_L, SENS_W, SENS_L, nTrain))\n",
    "            \n",
    "            print(\"Visualize collocated measurements\")\n",
    "            for j in range(2): # Training and test\n",
    "                for i in range(len(debug_vis_inds)):\n",
    "                    if j == 0:\n",
    "                        bkg_clean = bkg_clean_test_norm[:,:,:,:,:,debug_vis_inds[i]].cpu().detach().numpy()\n",
    "                        abs_clean = abs_clean_test_norm[:,:,:,:,:,debug_vis_inds[i]].cpu().detach().numpy()\n",
    "                        bkg_noisy = bkg_noisy_test[:,:,:,:,:,debug_vis_inds[i]].cpu().detach().numpy()\n",
    "                        abs_noisy = abs_noisy_test[:,:,:,:,:,debug_vis_inds[i]].cpu().detach().numpy()\n",
    "                        m_noisy_raw = m_noisy_test_raw[:,:,:,:,:,debug_vis_inds[i]].cpu().detach().numpy()\n",
    "                        m_noisy_norm = m_noisy_test_norm[:,:,:,:,:,debug_vis_inds[i]].cpu().detach().numpy()\n",
    "                        truth_debug = test_truth[:,:,debug_vis_inds[i]]\n",
    "                        title_str = \"test\"\n",
    "                    else:\n",
    "                        bkg_clean = bkg_clean_train_norm[:,:,:,:,:,debug_vis_inds[i]].cpu().detach().numpy()\n",
    "                        abs_clean = abs_clean_train_norm[:,:,:,:,:,debug_vis_inds[i]].cpu().detach().numpy()\n",
    "                        bkg_noisy = bkg_noisy_train[:,:,:,:,:,debug_vis_inds[i]].cpu().detach().numpy()\n",
    "                        abs_noisy = abs_noisy_train[:,:,:,:,:,debug_vis_inds[i]].cpu().detach().numpy()\n",
    "                        m_noisy_raw = m_noisy_train_raw[:,:,:,:,:,debug_vis_inds[i]].cpu().detach().numpy()\n",
    "                        m_noisy_norm = m_noisy_train_norm[:,:,:,:,:,debug_vis_inds[i]].cpu().detach().numpy()\n",
    "                        truth_debug = train_truth[:,:,debug_vis_inds[i]]\n",
    "                        title_str = \"train\"\n",
    "\n",
    "                    print(\"%s measurements\" % title_str)\n",
    "                    # Generate colocated measurements\n",
    "                    bkg_clean_coloc = np.zeros((SRC_W, SRC_L))\n",
    "                    abs_clean_coloc = np.zeros((SRC_W, SRC_L))\n",
    "                    bkg_noisy_coloc = np.zeros((SRC_W, SRC_L))\n",
    "                    abs_noisy_coloc = np.zeros((SRC_W, SRC_L))\n",
    "                    m_noisy_raw_coloc = np.zeros((SRC_W, SRC_L))\n",
    "                    m_noisy_norm_coloc = np.zeros((SRC_W, SRC_L))\n",
    "\n",
    "                    for sc in range(SRC_W):\n",
    "                        for sr in range(SRC_L):\n",
    "                            bkg_clean_coloc[sc, sr] = np.sum(bkg_clean[:,sc,sr,sc,sr])\n",
    "                            abs_clean_coloc[sc, sr] = np.sum(abs_clean[:,sc,sr,sc,sr])\n",
    "                            bkg_noisy_coloc[sc, sr] = np.sum(bkg_noisy[:,sc,sr,sc,sr])\n",
    "                            abs_noisy_coloc[sc, sr] = np.sum(abs_noisy[:,sc,sr,sc,sr])\n",
    "                            m_noisy_raw_coloc[sc, sr] = np.sum(m_noisy_raw[:,sc,sr,sc,sr])\n",
    "                            m_noisy_norm_coloc[sc, sr] = np.sum(m_noisy_norm[:,sc,sr,sc,sr])\n",
    "\n",
    "                    title_str_full = \"%s im %d\" % (title_str, debug_vis_inds[i])\n",
    "                    print(\"Tot # of background photons: %.2e\" % (int_time * pile_up))\n",
    "                    plt.figure(figsize=(30,3))\n",
    "                    plt.subplot(1,7,1)\n",
    "                    plt.imshow(truth_debug)\n",
    "                    plt.title(title_str_full)\n",
    "                    plt.axis(\"off\")\n",
    "                    _ = plt.colorbar()\n",
    "                    plt.subplot(1,7,2)\n",
    "                    plt.imshow(bkg_clean_coloc)\n",
    "                    plt.title(\"Bkg Clean\")\n",
    "                    plt.axis(\"off\")\n",
    "                    _ = plt.colorbar()\n",
    "                    plt.subplot(1,7,3)\n",
    "                    plt.imshow(abs_clean_coloc)\n",
    "                    plt.title(\"Abs Clean\")\n",
    "                    plt.axis(\"off\")\n",
    "                    _ = plt.colorbar()\n",
    "                    plt.subplot(1,7,4)\n",
    "                    plt.imshow(bkg_noisy_coloc)\n",
    "                    plt.title(\"Bkg Noisy\")\n",
    "                    plt.axis(\"off\")\n",
    "                    _ = plt.colorbar()\n",
    "                    plt.subplot(1,7,5)\n",
    "                    plt.imshow(abs_noisy_coloc)\n",
    "                    plt.title(\"Abs Noisy\")\n",
    "                    plt.axis(\"off\")\n",
    "                    _ = plt.colorbar()\n",
    "                    plt.subplot(1,7,6)\n",
    "                    plt.imshow(m_noisy_raw_coloc)\n",
    "                    plt.title(\"Meas (photon counts)\")\n",
    "                    plt.axis(\"off\")\n",
    "                    _ = plt.colorbar()\n",
    "                    plt.subplot(1,7,7)\n",
    "                    plt.imshow(m_noisy_norm_coloc)\n",
    "                    plt.title(\"Meas (normalized)\")\n",
    "                    plt.axis(\"off\")\n",
    "                    _ = plt.colorbar()\n",
    "                    plt.show()\n",
    "        print(\"\\n\")\n",
    "                \n",
    "                \n",
    "        # Visualize training and test sets\n",
    "        print(\"Visualize training and test sets\")\n",
    "        figure = plt.figure(figsize=(20, 8))\n",
    "        cols, rows = 6, 3\n",
    "        ncols_per_class = 3\n",
    "        train_rand_inds = random.sample(range(nTrain), rows*ncols_per_class)\n",
    "        test_rand_inds = random.sample(range(nTest), rows*ncols_per_class)\n",
    "        train_k = 0\n",
    "        test_k = 0\n",
    "        for i in range(1, cols * rows + 1):\n",
    "            if (((i-1) % cols) // ncols_per_class) > 0:\n",
    "                img = testTruth[:,test_rand_inds[test_k]]\n",
    "                im_title = \"Test\"\n",
    "                test_k += 1\n",
    "            else:\n",
    "                img = trainTruth[:,train_rand_inds[train_k]]\n",
    "                im_title = \"Train\"\n",
    "                train_k += 1\n",
    "            img = torch.reshape(img, (VOX_W, VOX_L))\n",
    "            figure.add_subplot(rows, cols, i)\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(im_title)\n",
    "            plt.imshow(img.squeeze())\n",
    "            plt.colorbar()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b632ba24-053d-4530-8066-6df34943a4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "# Train model\n",
    "\n",
    "# Send to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for L_i in range(len(nLayers)):\n",
    "\n",
    "    NL = nLayers[L_i]\n",
    "    \n",
    "    print(\"Running simulation %d/%d with %d layers\" % (L_i+1, len(nLayers), NL))\n",
    "    \n",
    "    # Set learning parameters\n",
    "    train_dict = {\"nLayers\": NL,\n",
    "                  \"scale_mag\": scale_initial_val,\n",
    "                  \"lam1\": lam1,\n",
    "                  \"LR\": LR,\n",
    "                  \"batch_sz\": batch_sz,\n",
    "                  \"nEpochs\": nEpochs,\n",
    "                  \"showEvery\": showEvery,\n",
    "                  \"untied\": untied,\n",
    "                  \"lossFunc\": lossFunc,\n",
    "                  \"vgg_weight\": vgg_weight,\n",
    "                  \"unet_nfilts\": unet_nfilts,}\n",
    "\n",
    "    # Perform training sequence\n",
    "    model, epoch_arr, train_losses, test_losses, misc_out = train_model(full_dataset, train_dict, device, A=None, visInds=displayIndices)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Test Trained model\n",
    "    min_thresh = 0.0\n",
    "\n",
    "    testMeas, testTruth = full_dataset.getFullTestSet()\n",
    "    trainMeas, trainTruth = full_dataset.getFullTrainSet()\n",
    "\n",
    "    cpu_dev = 'cpu'\n",
    "    model.to(cpu_dev)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if unet_nfilts > 0:\n",
    "            unet = misc_out[\"unet\"]\n",
    "            unet.send2dev(cpu_dev)\n",
    "            X_test_torch = unet(model(testMeas.to(cpu_dev)))\n",
    "\n",
    "            import math\n",
    "            nBatches = math.ceil(nTrain / batch_sz)\n",
    "            X_train_torch = torch.zeros(VOX_W*VOX_L, nTrain)\n",
    "            for b in range(nBatches):\n",
    "                b_start = b*batch_sz\n",
    "                b_end = (b+1)*batch_sz\n",
    "                X_train_torch[:,b_start:b_end] = unet(model(trainMeas[:,b_start:b_end].to(cpu_dev)))\n",
    "        else:\n",
    "            X_test_torch = model(testMeas.to(cpu_dev))\n",
    "            X_train_torch = model(trainMeas.to(cpu_dev))\n",
    "\n",
    "        meas_test_np = testMeas.cpu().detach().numpy()\n",
    "        recon_test_np = np.reshape(X_test_torch.cpu().detach().numpy(), (VOX_W, VOX_L, -1))\n",
    "        truth_test_np = np.reshape(testTruth.cpu().detach().numpy(), (VOX_W, VOX_L, -1))\n",
    "\n",
    "        meas_train_np = trainMeas.cpu().detach().numpy()\n",
    "        recon_train_np = np.reshape(X_train_torch.cpu().detach().numpy(), (VOX_W, VOX_L, -1))\n",
    "        truth_train_np = np.reshape(trainTruth.cpu().detach().numpy(), (VOX_W, VOX_L, -1))\n",
    "\n",
    "    print(\"Final reconstructions with clipping\")\n",
    "    final_recon_vis = recon_test_np[:,:,displayIndices]\n",
    "    showIms(final_recon_vis)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Save results\n",
    "\n",
    "    savepath = os.path.join(resultpath, 'sim')\n",
    "\n",
    "    if not (os.path.isdir(savepath)):\n",
    "        os.makedirs(savepath)\n",
    "\n",
    "    if untied:\n",
    "        untied_str = 'T'\n",
    "    else:\n",
    "        untied_str = 'F'\n",
    "    if vgg_weight > 0:\n",
    "        vgg_str = 'T'\n",
    "    else:\n",
    "        vgg_str = 'F'\n",
    "    model_savename = \"model_%s_train=%s_test=%s_NL=%d_nEpoch=%d_lossFunc=%s_untied=%s_vgg=%s_unet_nfilts=%d\" % (jac_dir, train_set_select, test_set_select, NL, nEpochs, lossFunc, untied_str, vgg_str, unet_nfilts)\n",
    "\n",
    "    fullsavepath_model = os.path.join(savepath, model_savename + '.pt')\n",
    "    fullsavepath_mat = os.path.join(savepath, model_savename + '.mat')\n",
    "\n",
    "    pydict = {\n",
    "        \"train_dict\": train_dict,\n",
    "        \"model\": model,\n",
    "        \"epoch_arr\": epoch_arr, \n",
    "        \"train_losses\": train_losses,\n",
    "        \"test_losses\": test_losses,\n",
    "        \"full_dataset\": full_dataset,\n",
    "    }\n",
    "\n",
    "    for k in misc_out:\n",
    "        pydict[k] = misc_out[k]\n",
    "\n",
    "    matdict = {\n",
    "        \"meas_test_np\": meas_test_np,\n",
    "        \"recon_test_np\": recon_test_np,\n",
    "        \"truth_test_np\": truth_test_np,\n",
    "        \"meas_train_np\": meas_train_np,\n",
    "        \"recon_train_np\": recon_train_np,\n",
    "        \"truth_train_np\": truth_train_np,\n",
    "        \"epoch_arr\": epoch_arr, \n",
    "        \"train_losses\": train_losses,\n",
    "        \"truthIms\": truth_test_np,\n",
    "        \"diff_meas\": meas_test_np[None,...],\n",
    "        \"test_losses\": test_losses,\n",
    "        \"J_mat_np\": J_mat_np,\n",
    "        \"Jheaders\": Jheaders_py,\n",
    "    }\n",
    "\n",
    "    torch.save(pydict, fullsavepath_model)\n",
    "    savemat(fullsavepath_mat, matdict)\n",
    "\n",
    "    print(\"Saved model to: %s\" % fullsavepath_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff20b0d-9338-46d5-8ad4-2d419c114022",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
