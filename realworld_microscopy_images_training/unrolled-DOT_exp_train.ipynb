{
 "cells": [
  {
   "cell_type": "code",
   "id": "2d9e325d-3f29-4317-8c33-214fd0c5b816",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-05-24T00:15:34.162501Z",
     "start_time": "2025-05-24T00:15:31.640439Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import savemat\n",
    "import configparser\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "setpaths_dir = \"../setpaths\"\n",
    "sys.path.append(setpaths_dir)\n",
    "from setpaths import setpaths\n",
    "libpath, datpath, resultpath, basepath = setpaths(setpaths_dir)\n",
    "\n",
    "# Add the correct paths\n",
    "actual_project_root = \"..\"  # /home/ubuntu/Unrolled-DOT\n",
    "actual_lib_path = \"../lib\"  # /home/ubuntu/Unrolled-DOT/lib\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(actual_project_root))\n",
    "sys.path.insert(0, os.path.abspath(actual_lib_path))\n",
    "\n",
    "# Now try the importnvidia-smi\n",
    "#from utils import getDatasetMat, train_model # if on lambda instance\n",
    "from lib.utils import getDatasetMat, train_model"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/unrolled-dot-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "12f8e047-6edb-4e4f-8863-1736c6cf27b5",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-05-24T00:15:35.961389Z",
     "start_time": "2025-05-24T00:15:35.941886Z"
    }
   },
   "source": [
    "rand_seed = 0\n",
    "np.random.seed(rand_seed)\n",
    "torch_seed = torch.manual_seed(rand_seed)\n",
    "\n",
    "GPUID = 1\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(GPUID)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "6e3afbf8-95e1-4106-853f-5abc6b0ca525",
   "metadata": {},
   "source": [
    "#### Load training and reconstruction parameters from configuration"
   ]
  },
  {
   "cell_type": "code",
   "id": "18c2c917-708a-4a88-9291-b41d3dd46867",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-05-24T00:15:37.792506Z",
     "start_time": "2025-05-24T00:15:37.768495Z"
    }
   },
   "source": [
    "# configname = \"tof_EML_dot_train_settings\"\n",
    "configname = \"exp_vgg_unet\"\n",
    "# configname = \"tof_dot_mismatch_settings\"\n",
    "# configname = \"tof_dot_confocal_settings\"\n",
    "\n",
    "fullconfigpath = os.path.join(\"settings\", configname + '.ini')\n",
    "config = configparser.ConfigParser()\n",
    "_ = config.read(fullconfigpath)\n",
    "\n",
    "# Set files to read from\n",
    "nTest = int(config[\"Settings\"][\"nTest\"])\n",
    "batch_sz = int(config[\"Settings\"][\"batch_sz\"])\n",
    "nEpochs = int(config[\"Settings\"][\"nEpochs\"])\n",
    "nLayers = int(config[\"Settings\"][\"nLayers\"])\n",
    "LR = float(config[\"Settings\"][\"LR\"])\n",
    "scale_initial_val = LR\n",
    "lam1 = config.get(\"Settings\", \"lam1\", fallback=None)\n",
    "untied = config[\"Settings\"].getboolean(\"untied\")\n",
    "lossFunc = config[\"Settings\"][\"lossFunc\"]\n",
    "showEvery = int(config[\"Settings\"][\"showEvery\"])\n",
    "measNormalization = float(config[\"Settings\"][\"measNormalization\"])\n",
    "loadFname = config[\"Settings\"][\"loadFname\"]\n",
    "datVarName = config[\"Settings\"][\"datVarName\"]\n",
    "actfunc = config[\"Settings\"][\"actfunc\"]\n",
    "vgg_weight = float(config[\"Settings\"][\"vgg_weight\"])\n",
    "unet_nfilts = int(config[\"Settings\"][\"unet_nfilts\"])\n",
    "displayIndices = [int(i) for i in config[\"Settings\"][\"displayIndices\"].split(',')]\n",
    "save_intermed = config[\"Settings\"].getboolean(\"save_intermed\", fallback=False)\n",
    "\n",
    "setJ = False\n",
    "if \"JVarName\" in config[\"Settings\"]:\n",
    "    JVarName = config[\"Settings\"][\"JVarName\"]\n",
    "    J_scale = float(config[\"Settings\"][\"J_scale\"])\n",
    "    setJ = True"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "c9ef77ab-8d57-44a3-9c29-de25e6e06dfd",
   "metadata": {},
   "source": [
    "#### Set up model and prepare for training"
   ]
  },
  {
   "cell_type": "code",
   "id": "f93afb14-d8e1-46e3-b6b3-ef42e1c70485",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T00:15:40.630688Z",
     "start_time": "2025-05-24T00:15:40.606730Z"
    }
   },
   "source": [
    "savepath = os.path.join(resultpath, 'exp')\n",
    "\n",
    "if untied:\n",
    "    untied_str = 'T'\n",
    "else:\n",
    "    untied_str = 'F'\n",
    "if vgg_weight > 0:\n",
    "    vgg_str = 'T'\n",
    "else:\n",
    "    vgg_str = 'F'\n",
    "    \n",
    "model_savename = \"model_%s_%s_NL=%d_nEpoch=%d_lossFunc=%s_untied=%s_vgg=%s_unet_nfilts=%d_act=%s\" % (loadFname, configname, nLayers, nEpochs, lossFunc, untied_str, vgg_str, unet_nfilts, actfunc)\n",
    "intermed_path = os.path.join(savepath, 'intermed_' + model_savename)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T00:16:13.984091Z",
     "start_time": "2025-05-24T00:15:49.060823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define file info\n",
    "repo_id = \"prajaktakini/human_protein_atlas_cells_dataset\" \n",
    "filename = \"hf_microscopy_dataset.mat\"\n",
    "local_dir = datpath  # your existing path variable\n",
    "\n",
    "# Download from Hugging Face Hub\n",
    "local_path = hf_hub_download(\n",
    "    repo_id=repo_id,\n",
    "    filename=filename,\n",
    "    repo_type=\"dataset\",\n",
    "    local_dir=local_dir,\n",
    "    local_dir_use_symlinks=False\n",
    ")\n",
    "\n",
    "print(\"✅ File downloaded to:\", local_path)"
   ],
   "id": "404f152612ed8cab",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/unrolled-dot-env/lib/python3.10/site-packages/huggingface_hub/file_download.py:980: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
      "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ File downloaded to: ../Unrolled-DOT-files/datapath/hf_microscopy_dataset.mat\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "d7bea52f-e1c6-430a-a86c-70e86344b7b1",
   "metadata": {
    "tags": [],
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2025-05-22T23:58:23.025742Z",
     "start_time": "2025-05-22T23:55:31.672269Z"
    }
   },
   "source": [
    "# Load in data              # Just the filename without .mat\n",
    "loadFpath = os.path.join(datpath, loadFname + '.mat')\n",
    "\n",
    "if setJ:\n",
    "    full_dataset, trainInds, testInds, J_mat = getDatasetMat(matpath=loadFpath, nTest=nTest, measNormalization=measNormalization, datVarName=datVarName, Jname=JVarName)\n",
    "    J_init = J_mat * (J_scale / np.amax(J_mat))\n",
    "else:\n",
    "    full_dataset, trainInds, testInds = getDatasetMat(matpath=loadFpath, nTest=nTest, measNormalization=measNormalization, datVarName=datVarName)\n",
    "    J_init = None\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_dict = {\"nLayers\": nLayers,\n",
    "              \"scale_mag\": scale_initial_val,\n",
    "              \"lam1\": lam1,\n",
    "              \"actfunc\": actfunc,\n",
    "              \"LR\": LR,\n",
    "              \"batch_sz\": batch_sz,\n",
    "              \"nEpochs\": nEpochs,\n",
    "              \"showEvery\": showEvery,\n",
    "              \"untied\": untied,\n",
    "              \"lossFunc\": lossFunc,\n",
    "              \"vgg_weight\": vgg_weight,\n",
    "              \"unet_nfilts\": unet_nfilts,\n",
    "              \"measNormalization\": measNormalization,\n",
    "             }\n",
    "\n",
    "if save_intermed:\n",
    "    if not (os.path.isdir(intermed_path)):\n",
    "        os.makedirs(intermed_path)\n",
    "    train_dict['intermed_path'] = intermed_path\n",
    "\n",
    "model, epoch_arr, train_losses, test_losses, misc_out = train_model(dataset_in=full_dataset, \n",
    "                                                        train_d=train_dict, dev=device, A=J_init, visInds=displayIndices)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c86b038-caed-40f9-b8dd-034856ee1ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test results\n",
    "\n",
    "Y_test_torch, truthIms_torch = full_dataset.getFullTestSet()\n",
    "_, _, _, imY, imX = full_dataset.getDims()\n",
    "nIms = Y_test_torch.shape[1]\n",
    "\n",
    "model = model.to('cpu')\n",
    "Y_test_torch = Y_test_torch.cpu()\n",
    "if unet_nfilts > 0:\n",
    "    unet = misc_out['unet'].to('cpu')\n",
    "\n",
    "starttime = time.perf_counter()\n",
    "reconIms = model(Y_test_torch)\n",
    "if unet_nfilts > 0:\n",
    "    reconIms = unet(reconIms)\n",
    "finishtime = time.perf_counter()\n",
    "reconTime = finishtime - starttime\n",
    "\n",
    "reconIms_np = np.reshape(reconIms.detach().numpy(), (imY, imX, nIms))\n",
    "truthIms_np = truthIms_torch.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bcc2b7-611d-4936-8e86-c020ac322dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (os.path.isdir(savepath)):\n",
    "    os.makedirs(savepath)\n",
    "\n",
    "fullsavepath_model = os.path.join(savepath, model_savename + '.pt')\n",
    "\n",
    "pydict = {\n",
    "    \"full_dataset\": full_dataset,\n",
    "    \"train_dict\": train_dict,\n",
    "    \"model\": model,\n",
    "    \"epoch_arr\": epoch_arr, \n",
    "    \"train_losses\": train_losses,\n",
    "    \"test_losses\": test_losses,\n",
    "    \"trainInds\": trainInds,\n",
    "    \"testInds\": testInds,\n",
    "}\n",
    "for k in misc_out:\n",
    "    pydict[k] = misc_out[k]\n",
    "\n",
    "matdict = {\n",
    "    \"epoch_arr\": epoch_arr, \n",
    "    \"train_losses\": train_losses,\n",
    "    \"test_losses\": test_losses,\n",
    "    \"trainInds\": trainInds,\n",
    "    \"testInds\": testInds,\n",
    "    \"reconIms_np\": reconIms_np,\n",
    "    \"truthIms_np\": truthIms_np,\n",
    "    \"runtime_arr\": misc_out[\"runtime_arr\"],\n",
    "}\n",
    "\n",
    "torch.save(pydict, fullsavepath_model)\n",
    "\n",
    "fullsavepath_mat = os.path.join(savepath, model_savename + '.mat')\n",
    "savemat(fullsavepath_mat, matdict)\n",
    "\n",
    "print(\"Saved model to: %s\" % fullsavepath_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629e30c8-957a-42ef-b5e1-dcd513bdbb86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
